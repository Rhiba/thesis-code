{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df76856e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "import numpy as np\n",
    "import deepbayesHF\n",
    "import deepbayesHF.optimizers as optimizers\n",
    "from deepbayesHF import PosteriorModel\n",
    "from deepbayesHF.analyzers import FGSM\n",
    "from deepbayesHF.analyzers import eps_LRP\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "import cv2\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple\n",
    "\n",
    "import subprocess\n",
    "from statistics import mode\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d254de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_number(X,SCALE):\n",
    "    X = X.reshape(SCALE[0],SCALE[1],3)\n",
    "    plt.imshow(X,cmap='gray')\n",
    "    plt.show()\n",
    "    \n",
    "def display_explanation(x0,SCALE,expl):\n",
    "    fig, (ax1,ax2,ax3) = plt.subplots(1,3)\n",
    "    x0_2d = x0.reshape(SCALE[0],SCALE[1],3)\n",
    "    ax1.set_title('Input')\n",
    "    ax1.imshow(x0_2d,cmap='gray')\n",
    "    expl_2d = expl.reshape(SCALE[0],SCALE[1],3)\n",
    "    ax2.set_title('Explanation')\n",
    "    ax2.imshow(expl_2d)\n",
    "    \n",
    "    cmap = plt.cm.gray\n",
    "    norm = plt.Normalize(x0.min(),x0.max())\n",
    "    rgba = cmap(norm(x0))\n",
    "    \n",
    "    norm_ex = plt.Normalize(expl.min(),expl.max())\n",
    "    normed_ex = norm_ex(expl)\n",
    "    \n",
    "    for i,x in enumerate(normed_ex):\n",
    "        if x > 0:\n",
    "            rgba[i] = x,0,0,1\n",
    "    \n",
    "    rgba = rgba.reshape(SCALE[0],SCALE[1],4)\n",
    "    \n",
    "    ax3.set_title('Overlayed')\n",
    "    ax3.imshow(rgba,interpolation='nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4190aa74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load mnist data and scale down to SCALE (trying 14x14 initially)\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "SCALE = (14,14)\n",
    "if not SCALE == X_train[0].shape:\n",
    "    X_train = np.array(list(map(lambda x:cv2.resize(x,SCALE,interpolation=cv2.INTER_CUBIC),X_train)))\n",
    "X_train = np.array(list(map(lambda x:cv2.cvtColor(x,cv2.COLOR_GRAY2RGB),X_train)))\n",
    "X_train = X_train/255.\n",
    "X_train = X_train.astype(\"float32\").reshape(len(X_train), SCALE[0],SCALE[1],3)\n",
    "\n",
    "if not SCALE == X_test.shape:\n",
    "    X_test = np.array(list(map(lambda x:cv2.resize(x,SCALE,interpolation=cv2.INTER_CUBIC),X_test)))\n",
    "X_test = np.array(list(map(lambda x:cv2.cvtColor(x,cv2.COLOR_GRAY2RGB),X_test)))\n",
    "X_test = X_test/255.\n",
    "X_test = X_test.astype(\"float32\").reshape(len(X_test), SCALE[0], SCALE[1],3)\n",
    "\n",
    "# # make it a binary classification task (X or not X)\n",
    "# target = 8\n",
    "# y_train = np.array([1 if y == target else 0 for y in y_train])\n",
    "# y_test = np.array([1 if y == target else 0 for y in y_test])\n",
    "\n",
    "# # filter so we get about 50% target class and 50% other\n",
    "# target_idxs = [i for i in range(len(y_train)) if y_train[i] == 1]\n",
    "# other_idxs = [i for i in range(len(y_train)) if y_train[i] == 0]\n",
    "\n",
    "# #uncomment the shuffle for training only\n",
    "# #random.shuffle(other_idxs)\n",
    "# other_idxs = other_idxs[:len(target_idxs)]\n",
    "# # pick len(target_idxs) samples from the other_idxs\n",
    "# X_train = np.array([x for i,x in enumerate(X_train) if i in other_idxs or i in target_idxs])\n",
    "# y_train = np.array([y for i,y in enumerate(y_train) if i in other_idxs or i in target_idxs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c7eab0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_name = f'mnist{SCALE[0]}x{SCALE[1]}_32_16_coverage_rgb_tmp'\n",
    "opt = optimizers.VariationalOnlineGuassNewton()\n",
    "likelihood = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "inputs = Input(shape=X_train[0].shape)\n",
    "tmp = Flatten()(inputs)\n",
    "tmp = Dense(256,activation='relu')(tmp)\n",
    "tmp = Dense(128,activation='relu')(tmp)\n",
    "predictions = Dense(10,activation='softmax')(tmp)\n",
    "model = Model(inputs=inputs,outputs=predictions)\n",
    "\n",
    "bayes_model = opt.compile(model,loss_fn=likelihood,\n",
    "                          epochs=5, learning_rate=0.25,\n",
    "                          inflate_prior=2.0, log_file='tmp/log.txt')\n",
    "bayes_model.train(X_train,y_train,X_test,y_test)\n",
    "bayes_model.save(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba14b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = f'mnist{SCALE[0]}x{SCALE[1]}_32_16_coverage_rgb_tmp'\n",
    "bayes_model = PosteriorModel(model_name)\n",
    "y_pred = bayes_model.predict(X_test,n=50)\n",
    "check_accuracy = tf.keras.metrics.Accuracy(name=\"train_acc\")\n",
    "check_accuracy(y_test,np.argmax(y_pred,axis=1))\n",
    "print()\n",
    "print('Loaded model accuracy:',f'{check_accuracy.result().numpy()*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4db7dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 50\n",
    "# pick a random positive input for testing\n",
    "n = 0\n",
    "\n",
    "while True:\n",
    "    n = np.random.choice(list(range(len(X_train))))\n",
    "    if y_train[n] == 8:\n",
    "        break\n",
    "\n",
    "\n",
    "X = X_train[n].reshape(1,SCALE[0],SCALE[1],3).astype(np.float32)\n",
    "y_hat = np.argmax(bayes_model.predict(X,n=N))\n",
    "display_number(X,SCALE)\n",
    "print('Prediction:',y_hat)\n",
    "input_shape = X.flatten().shape\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0a7c75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# naive method of generating a bayesian explanation\n",
    "\n",
    "sys.path.append(\"../../LayerwiseRelevancePropagation/src\")\n",
    "from lrp import RelevancePropagation\n",
    "import math\n",
    "\n",
    "\n",
    "exps = []\n",
    "X = X_train[n]\n",
    "X = X.reshape(1,SCALE[0],SCALE[1],3)\n",
    "for j in range(50):\n",
    "    bayes_model.set_weights(bayes_model.sample())\n",
    "    y = np.argmax(np.array(bayes_model._predict(X)).flatten())\n",
    "\n",
    "    lrp = RelevancePropagation(0.01,'max',True,X.shape,bayes_model.model)\n",
    "    exp = lrp.run(X.reshape(*X.shape[1:]))\n",
    "    #print(exp)\n",
    "    #plt.imshow(exp,vmin=0,vmax=1)\n",
    "    #plt.show()\n",
    "\n",
    "    exp_pop_flat = np.array([i for i in exp.flatten().flatten() if i > 0])\n",
    "    max_rel = np.max(exp_pop_flat)\n",
    "    av_rel = np.mean(exp_pop_flat)\n",
    "    var_rel = np.var(exp_pop_flat)\n",
    "    #print('Over populated spaces:')\n",
    "    #print('Max:',max_rel,'Average:',av_rel,'Variance:',var_rel)\n",
    "\n",
    "    limit = 0.6*max_rel\n",
    "    #limit = 0\n",
    "    exp[exp < limit] = 0\n",
    "    exp[exp > 0] = 1\n",
    "    #plt.imshow(exp)\n",
    "    #plt.show()\n",
    "    exps.append(exp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a624e5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualise results\n",
    "cmap = dict()\n",
    "names = []\n",
    "es = []\n",
    "for e in exps:\n",
    "    if not str(e) in names:\n",
    "        names.append(str(e))\n",
    "        es.append(e)\n",
    "        cmap[names.index(str(e))] = 0\n",
    "    cmap[names.index(str(e))] += 1\n",
    "\n",
    "res = max(cmap,key=cmap.get)\n",
    "res_image = es[res]\n",
    "plt.imshow(res_image)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "cov = (cmap[res]/50)*100\n",
    "\n",
    "print(\"P_cover:\",cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500352e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# better way of generating a bayesian explanation\n",
    "\n",
    "sys.path.append(\"../../LayerwiseRelevancePropagation/src\")\n",
    "from lrp import RelevancePropagation\n",
    "import math\n",
    "\n",
    "from memo import memo\n",
    "\n",
    "@memo\n",
    "def generate_min_exps(expl,threshold):\n",
    "    exps = []\n",
    "    for i in range(len(expl)):\n",
    "        orig_expl = expl\n",
    "        if orig_expl[i] == 0:\n",
    "            continue\n",
    "        else:\n",
    "            if i == len(expl) - 1:\n",
    "                s = sum(orig_expl[:i])\n",
    "            else:\n",
    "                s = sum(orig_expl[:i])+sum(orig_expl[i+1:])\n",
    "            if s < threshold:\n",
    "                exps.append(expl)\n",
    "                break\n",
    "            else:\n",
    "                new_expl = tuple(orig_expl[:i]) + (0,)\n",
    "                if i < len(expl)-1:\n",
    "                    new_expl = new_expl + tuple(orig_expl[i+1:])\n",
    "                new_exps = generate_min_exps(new_expl,threshold)\n",
    "                exps += new_exps\n",
    "    return exps\n",
    "exps = []\n",
    "X = X_train[n]\n",
    "X = X.reshape(1,SCALE[0],SCALE[1],3)\n",
    "for j in range(2):\n",
    "    bayes_model.set_weights(bayes_model.sample())\n",
    "    X = X.reshape(1,SCALE[0],SCALE[1],3)\n",
    "    y = np.argmax(np.array(bayes_model._predict(X)).flatten())\n",
    "\n",
    "    lrp = RelevancePropagation(0.05,'max',True,X.shape,bayes_model.model)\n",
    "    exp = lrp.run(X.reshape(*X.shape[1:]))\n",
    "    #plt.imshow(exp,vmin=0,vmax=1)\n",
    "    #plt.show()\n",
    "\n",
    "    exp_pop_flat = np.array([i for i in exp.flatten().flatten() if i > 0])\n",
    "    max_rel = np.max(exp_pop_flat)\n",
    "    av_rel = np.mean(exp_pop_flat)\n",
    "    var_rel = np.var(exp_pop_flat)\n",
    "\n",
    "    limit =0.3*max_rel\n",
    "    exp[exp < limit] = 0\n",
    "\n",
    "    exp_list = set(generate_min_exps(tuple(exp.flatten()),0.9*np.sum(exp)))\n",
    "    exps += exp_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1896b39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualise results\n",
    "print(len(exps))\n",
    "cmap = dict()\n",
    "names = []\n",
    "es = []\n",
    "for e in exps:\n",
    "    e = np.array(e)\n",
    "    e[e > 0 ] = 1\n",
    "    if not str(e) in names:\n",
    "        names.append(str(e))\n",
    "        es.append(e)\n",
    "        cmap[names.index(str(e))] = 0\n",
    "    cmap[names.index(str(e))] += 1\n",
    "\n",
    "res = max(cmap,key=cmap.get)\n",
    "res_image = es[res]\n",
    "plt.imshow(np.array(res_image).reshape(SCALE[0],SCALE[1]))\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "cov = (cmap[res]/50)*100\n",
    "\n",
    "print(\"P_cover:\",cov)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
