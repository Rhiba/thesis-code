{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01baea2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../shap')\n",
    "import shap\n",
    "\n",
    "import os\n",
    "sys.path.append('../..')\n",
    "import numpy as np\n",
    "import deepbayesHF\n",
    "import deepbayesHF.optimizers as optimizers\n",
    "from deepbayesHF import PosteriorModel\n",
    "from deepbayesHF.analyzers import FGSM\n",
    "from deepbayesHF.analyzers import eps_LRP\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "import cv2\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple\n",
    "\n",
    "import subprocess\n",
    "from statistics import mode\n",
    "import json\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5bbe8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_number(X):\n",
    "    X = X.reshape(X.shape[1],X.shape[2])\n",
    "    plt.imshow(X,cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e80bee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load mnist data and scale down to SCALE (trying 14x14 initially)\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "SCALE = (14,14)\n",
    "if not SCALE == X_train[0].shape:\n",
    "    X_train = np.array(list(map(lambda x:cv2.resize(x,SCALE,interpolation=cv2.INTER_CUBIC),X_train)))\n",
    "X_train = np.array(list(map(lambda x:cv2.cvtColor(x,cv2.COLOR_GRAY2RGB),X_train)))\n",
    "X_train = X_train/255.\n",
    "X_train = X_train.astype(\"float32\").reshape(len(X_train), SCALE[0],SCALE[1],3)\n",
    "\n",
    "if not SCALE == X_test.shape:\n",
    "    X_test = np.array(list(map(lambda x:cv2.resize(x,SCALE,interpolation=cv2.INTER_CUBIC),X_test)))\n",
    "X_test = np.array(list(map(lambda x:cv2.cvtColor(x,cv2.COLOR_GRAY2RGB),X_test)))\n",
    "X_test = X_test/255.\n",
    "X_test = X_test.astype(\"float32\").reshape(len(X_test), SCALE[0], SCALE[1],3)\n",
    "\n",
    "# make it a binary classification task (X or not X)\n",
    "# target = 8\n",
    "# y_train = np.array([1 if y == target else 0 for y in y_train])\n",
    "# y_test = np.array([1 if y == target else 0 for y in y_test])\n",
    "\n",
    "# # filter so we get about 50% target class and 50% other\n",
    "# target_idxs = [i for i in range(len(y_train)) if y_train[i] == 1]\n",
    "# other_idxs = [i for i in range(len(y_train)) if y_train[i] == 0]\n",
    "\n",
    "# #uncomment the shuffle for training only\n",
    "# #random.shuffle(other_idxs)\n",
    "# other_idxs = other_idxs[:len(target_idxs)]\n",
    "# # pick len(target_idxs) samples from the other_idxs\n",
    "# X_train = np.array([x for i,x in enumerate(X_train) if i in other_idxs or i in target_idxs])\n",
    "# y_train = np.array([y for i,y in enumerate(y_train) if i in other_idxs or i in target_idxs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0739bff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = f'MNIST_SHAP_fullsize'\n",
    "\n",
    "opt = optimizers.VariationalOnlineGuassNewton()\n",
    "likelihood = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=(28, 28, 1)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "bayes_model = opt.compile(model,loss_fn=likelihood,\n",
    "                          epochs=5, learning_rate=0.25,\n",
    "                          inflate_prior=2.0, log_file='tmp/log.txt')\n",
    "\n",
    "bayes_model.train(X_train,y_train,X_test,y_test)\n",
    "bayes_model.save(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9061d03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = f'mnist{SCALE[0]}x{SCALE[1]}_32_16_coverage_rgb_tmp'\n",
    "bayes_model = PosteriorModel(model_name)\n",
    "y_pred = bayes_model.predict(X_test,n=50)\n",
    "check_accuracy = tf.keras.metrics.Accuracy(name=\"train_acc\")\n",
    "check_accuracy(y_test,np.argmax(y_pred,axis=1))\n",
    "print()\n",
    "print('Loaded model accuracy:',f'{check_accuracy.result().numpy()*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3476f818",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 50\n",
    "# pick a random correctly classified input for testing\n",
    "n = 0\n",
    "while True:\n",
    "    n = np.random.randint(len(y_train))\n",
    "    X = X_train[n].reshape(1,SCALE[0],SCALE[1],3).astype(float)\n",
    "    y_hat = np.argmax(bayes_model.predict(X,n=N))\n",
    "    y_class = y_hat\n",
    "    if y_hat == y_train[n]:\n",
    "        break\n",
    "        \n",
    "plt.imshow(X.reshape(*SCALE,3))\n",
    "plt.show()\n",
    "print('Prediction:',y_class)\n",
    "input_shape = X.flatten().shape\n",
    "\n",
    "print(\"Index:\",n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891c2f68",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# naive bayesian explanation method\n",
    "\n",
    "X = X_train[n].reshape(1,*SCALE,3).astype(float)\n",
    "exps = []\n",
    "for i in range(50):\n",
    "    background = X_train[np.random.choice(X_train.shape[0],100,replace=False)]\n",
    "    bayes_model.set_weights(bayes_model.sample())\n",
    "    model = bayes_model.model\n",
    "    e = shap.DeepExplainer(model,background)\n",
    "    shap_values = e.shap_values(X)\n",
    "    exp = shap_values[y_train[n]].reshape(*SCALE,3)[:,:,0]\n",
    "    max_rel = np.max(exp)\n",
    "    limit = 0.2*max_rel\n",
    "    #limit = 0\n",
    "    exp[exp < limit] = 0\n",
    "    exp[exp > 0] = 1\n",
    "    exps.append(exp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7230e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualise result\n",
    "cmap = dict()\n",
    "names = []\n",
    "es = []\n",
    "for e in exps:\n",
    "    if not str(e) in names:\n",
    "        names.append(str(e))\n",
    "        es.append(e)\n",
    "        cmap[names.index(str(e))] = 0\n",
    "    cmap[names.index(str(e))] += 1\n",
    "\n",
    "res = max(cmap,key=cmap.get)\n",
    "res_image = es[res]\n",
    "plt.imshow(res_image)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "cov = (cmap[res]/50)*100\n",
    "\n",
    "print(\"P_cover:\",cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18c6b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from memo import memo\n",
    "\n",
    "@memo\n",
    "def generate_min_exps(expl,threshold):\n",
    "    exps = []\n",
    "    for i in range(len(expl)):\n",
    "        orig_expl = expl\n",
    "        if orig_expl[i] == 0:\n",
    "            continue\n",
    "        else:\n",
    "            if i == len(expl) - 1:\n",
    "                s = sum(orig_expl[:i])\n",
    "            else:\n",
    "                s = sum(orig_expl[:i])+sum(orig_expl[i+1:])\n",
    "            if s < threshold:\n",
    "                exps.append(expl)\n",
    "                break\n",
    "            else:\n",
    "                new_expl = tuple(orig_expl[:i]) + (0,)\n",
    "                if i < len(expl)-1:\n",
    "                    new_expl = new_expl + tuple(orig_expl[i+1:])\n",
    "                new_exps = generate_min_exps(new_expl,threshold)\n",
    "                exps += new_exps\n",
    "    return exps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d29028f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# better method of generating Bayesian explanation\n",
    "\n",
    "X = X_train[n].reshape(1,*SCALE,3).astype(float)\n",
    "exps = []\n",
    "for i in range(50):\n",
    "    background = X_train[np.random.choice(X_train.shape[0],100,replace=False)]\n",
    "    bayes_model.set_weights(bayes_model.sample())\n",
    "    model = bayes_model.model\n",
    "    e = shap.DeepExplainer(model,background)\n",
    "    shap_values = e.shap_values(X)\n",
    "    exp = shap_values[y_train[n]].reshape(*SCALE,3)[:,:,0]\n",
    "    max_rel = np.max(exp)\n",
    "    limit = 0.2*max_rel\n",
    "    #limit = 0\n",
    "    exp[exp < limit] = 0\n",
    "    exp[exp > 0] = 1\n",
    "    exp_list = list(set(generate_min_exps(tuple(exp.flatten()),0.88*np.sum(exp))))\n",
    "    exps += exp_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53f78d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualise results\n",
    "cmap = dict()\n",
    "pic_map = dict()\n",
    "print(len(exps))\n",
    "for e in exps:\n",
    "    e = np.array(e)\n",
    "    if not str(e) in cmap.keys():\n",
    "        cmap[str(e)] = 0\n",
    "        pic_map[str(e)] = np.array(e).reshape(*SCALE)\n",
    "    else:\n",
    "        print('dupe')\n",
    "    cmap[str(e)] += 1\n",
    "\n",
    "res = max(cmap,key=cmap.get)\n",
    "res_image = pic_map[res]\n",
    "plt.imshow(res_image)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "cov = (cmap[res]/50)*100\n",
    "\n",
    "print(\"P_cover:\",cov)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
