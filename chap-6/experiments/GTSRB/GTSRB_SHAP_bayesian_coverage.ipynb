{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6616c0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../shap')\n",
    "import shap\n",
    "\n",
    "import os\n",
    "sys.path.append('../..')\n",
    "import numpy as np\n",
    "import deepbayesHF\n",
    "import deepbayesHF.optimizers as optimizers\n",
    "from deepbayesHF import PosteriorModel\n",
    "from deepbayesHF.analyzers import FGSM\n",
    "from deepbayesHF.analyzers import eps_LRP\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "import cv2\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import subprocess\n",
    "from statistics import mode\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335a4438",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = [], []\n",
    "\n",
    "widths = []\n",
    "heights = []\n",
    "train_dir = '/home/rhiba/bayesian-ores/training_data/gtsrb/Final_Training/Images/'\n",
    "for class_dir in os.listdir(train_dir):\n",
    "    classid = int(class_dir)\n",
    "    full_path = os.path.join(train_dir,class_dir)\n",
    "    images = [x for x in os.listdir(full_path) if x.endswith('.ppm')]\n",
    "    for i in images:\n",
    "        actual_image = imageio.imread(os.path.join(full_path,i))\n",
    "        widths.append(len(actual_image[0]))\n",
    "        heights.append(len(actual_image))\n",
    "        X_train.append(actual_image)\n",
    "        y_train.append(classid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6797808",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Min and max widths:',min(widths),max(widths))\n",
    "print('Min and max heights:',min(heights),max(heights))\n",
    "rescale_size = (30,30)\n",
    "print('Rescaling to:',rescale_size)\n",
    "\n",
    "if not rescale_size == X_train[0].shape:\n",
    "    X_train = np.array(list(map(lambda x:cv2.resize(x,rescale_size,interpolation=cv2.INTER_CUBIC),X_train)))\n",
    "X_train = X_train/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e8f0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "zipped = list(zip(X_train,y_train))\n",
    "#random.shuffle(zipped)\n",
    "X_train = list(list(zip(*zipped))[0])\n",
    "y_train = list(list(zip(*zipped))[1])\n",
    "split_point = int(0.8*len(X_train))\n",
    "X_test = X_train[split_point:]\n",
    "X_train = X_train[:split_point]\n",
    "y_test = y_train[split_point:]\n",
    "y_train = y_train[:split_point]\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05f6790",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = f'GTSRB_SHAP_30x30'\n",
    "\n",
    "opt = optimizers.VariationalOnlineGuassNewton()\n",
    "likelihood = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "inputs = Input(shape=X_train[0].shape)\n",
    "tmp = Conv2D(4,3,padding='same',activation='relu')(inputs)\n",
    "tmp = MaxPooling2D()(tmp)\n",
    "tmp = Conv2D(8,3,padding='same',activation='relu')(tmp)\n",
    "tmp = MaxPooling2D()(tmp)\n",
    "tmp = Flatten()(tmp)\n",
    "tmp = Dense(128,activation='relu')(tmp)\n",
    "predictions = Dense(43,activation='softmax')(tmp)\n",
    "model = Model(inputs=inputs,outputs=predictions)\n",
    "\n",
    "bayes_model = opt.compile(model,loss_fn=likelihood,\n",
    "                          epochs=25, learning_rate=0.25,\n",
    "                          inflate_prior=2.0, log_file='tmp/log.txt')\n",
    "bayes_model.train(X_train,y_train,X_test,y_test)\n",
    "bayes_model.save(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d006ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = f'GTSRB_SHAP_30x30'\n",
    "bayes_model = PosteriorModel(model_name)\n",
    "y_pred = bayes_model.predict(X_test[:50],n=50)\n",
    "check_accuracy = tf.keras.metrics.Accuracy(name=\"train_acc\")\n",
    "check_accuracy(y_test[:50],np.argmax(y_pred,axis=1))\n",
    "print()\n",
    "print('Loaded model accuracy:',f'{check_accuracy.result().numpy()*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04ec837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get random input\n",
    "N = 50\n",
    "n = 0\n",
    "while True:\n",
    "    n = np.random.randint(0,len(y_train))\n",
    "    n = 4137\n",
    "    X = X_train[n].reshape(1,*X_train[n].shape).astype(float)\n",
    "\n",
    "    \n",
    "    #### GET CORRECTLY CLASSIFIED INPUT \n",
    "    y_hat = np.argmax(bayes_model.predict(X,n=N))\n",
    "    if y_train[n] == y_hat:\n",
    "        break\n",
    "    \n",
    "\n",
    "plt.imshow(X_train[n],vmin=0,vmax=1)\n",
    "print('Prediction:',y_hat)\n",
    "print('n:',n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd65e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get shap explanations from model samples\n",
    "\n",
    "background = X_train[np.random.choice(X_train.shape[0],200,replace=False)]\n",
    "\n",
    "if not os.path.exists(f'exps/exp{n}'):\n",
    "    os.mkdir(f'exps/exp{n}')\n",
    "    \n",
    "input_path = f'exps/exp{n}/X.npy'\n",
    "background_path = f'exps/exp{n}/bg.npy'\n",
    "y_path = f'exps/exp{n}/y.npy'\n",
    "np.save(y_path,y_hat,False)\n",
    "np.save(input_path,X,False)\n",
    "np.save(background_path,background,False)\n",
    "\n",
    "iterations = 50\n",
    "for i in range(iterations):\n",
    "    subprocess.Popen(['python3','get_SHAP_exp.py',str(i),model_name,input_path,f'exps/exp{n}',background_path])\n",
    "        \n",
    "full = False \n",
    "while not full:\n",
    "    if len([name for name in os.listdir(f'exps/exp{n}') if os.path.isfile(os.path.join(f'exps/exp{n}', name))]) == iterations+2:\n",
    "        full = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10a9287",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in and process the results from the above, naive bayesian explanation method\n",
    "\n",
    "all_exps = []\n",
    "for f in os.listdir(f'exps/exp{n}'):\n",
    "    if os.path.isfile(os.path.join(f'exps/exp{n}',f)) and not f.startswith('X') and not f.startswith('bg') and not f.startswith('y'):\n",
    "        tmp = np.load(os.path.join(f'exps/exp{n}',f))\n",
    "        # the shap.image_plot function only works with an outer list, not np array (no idea why, its the same shape)\n",
    "        if tmp.shape == (43,1,30,30,3):\n",
    "            tmp = tmp[y_train[n]].reshape(30,30,3)[:,:,0]\n",
    "            all_exps.append(tmp)\n",
    "\n",
    "coverage_map = dict()\n",
    "max_rel = np.max(all_exps)\n",
    "limit = 0.004*max_rel\n",
    "for exp in all_exps:\n",
    "    exp[exp < limit] = 0\n",
    "    exp[exp > 0] = 1\n",
    "    #plt.imshow(exp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5417bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualise results\n",
    "cmap = dict()\n",
    "names = []\n",
    "es = []\n",
    "for e in all_exps:\n",
    "    if not str(e) in names:\n",
    "        names.append(str(e))\n",
    "        es.append(e)\n",
    "        cmap[names.index(str(e))] = 0\n",
    "    cmap[names.index(str(e))] += 1\n",
    "\n",
    "res = max(cmap,key=cmap.get)\n",
    "res_image = es[res]\n",
    "plt.imshow(res_image)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "cov = (cmap[res]/50)*100\n",
    "\n",
    "print(\"P_cover:\",cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77c52b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from memo import memo\n",
    "\n",
    "@memo\n",
    "def generate_min_exps(expl,threshold):\n",
    "    exps = []\n",
    "    for i in range(len(expl)):\n",
    "        orig_expl = expl\n",
    "        if orig_expl[i] == 0:\n",
    "            continue\n",
    "        else:\n",
    "            if i == len(expl) - 1:\n",
    "                s = sum(orig_expl[:i])\n",
    "            else:\n",
    "                s = sum(orig_expl[:i])+sum(orig_expl[i+1:])\n",
    "            if s < threshold:\n",
    "                exps.append(expl)\n",
    "                break\n",
    "            else:\n",
    "                new_expl = tuple(orig_expl[:i]) + (0,)\n",
    "                if i < len(expl)-1:\n",
    "                    new_expl = new_expl + tuple(orig_expl[i+1:])\n",
    "                new_exps = generate_min_exps(new_expl,threshold)\n",
    "                exps += new_exps\n",
    "    return exps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14644f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# better method of generating bayesian cover exp\n",
    "import ast\n",
    "\n",
    "all_exps = []\n",
    "for f in os.listdir(f'exps/exp{n}'):\n",
    "    if os.path.isfile(os.path.join(f'exps/exp{n}',f)) and not f.startswith('X') and not f.startswith('bg') and not f.startswith('y'):\n",
    "        tmp = np.load(os.path.join(f'exps/exp{n}',f))\n",
    "        # the shap.image_plot function only works with an outer list, not np array (no idea why, its the same shape)\n",
    "        if tmp.shape == (43,1,30,30,3):\n",
    "            tmp = tmp[y_train[n]].reshape(30,30,3)[:,:,0]\n",
    "            all_exps.append(tmp)\n",
    "\n",
    "net_count = len(all_exps)\n",
    "#print(net_count)\n",
    "coverage_map = dict()\n",
    "max_rel = np.max(all_exps)\n",
    "limit = 0.004*max_rel\n",
    "all_new_exps = []\n",
    "for exp in all_exps[:3]+all_exps[4:5]:\n",
    "    print(exp.shape)\n",
    "    exp[exp < limit] = 0\n",
    "    exp[exp > 0] = 1\n",
    "    exp_list = list(set(generate_min_exps(tuple(exp.flatten()),0.98*np.sum(exp))))\n",
    "    all_new_exps += exp_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f3047f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualise results\n",
    "cmap = dict()\n",
    "pic_map = dict()\n",
    "print(len(exps))\n",
    "for e in all_new_exps:\n",
    "    e = np.array(e)\n",
    "    if not str(e) in cmap.keys():\n",
    "        cmap[str(e)] = 0\n",
    "        pic_map[str(e)] = np.array(e).reshape(30,30)\n",
    "    #else:\n",
    "    #    print('dupe')\n",
    "    cmap[str(e)] += 1\n",
    "\n",
    "res = max(cmap,key=cmap.get)\n",
    "res_image = pic_map[res]\n",
    "plt.imshow(res_image)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "cov = (cmap[res]/50)*100\n",
    "\n",
    "print(\"P_cover:\",cov)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
